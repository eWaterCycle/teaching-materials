{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Calibrate HBV model with ERA5 forcing and GRDC observation\n",
    "\n",
    "In this notebook you will calibrate your own HBV model using ERA5 forcing data (from the previous notebook) and GRDC observation data. You will have to change a few settings below. Only a very simple (bad!) calibration is provided. It is up to you to optimize the calibration for your specific region. Read carefully and decide which inputs and lines to change.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all dependencies, including your own model through ewatercycle_wrapper_HBV\n",
    "import ewatercycle.forcing\n",
    "import ewatercycle.observation.grdc\n",
    "import ewatercycle.analysis\n",
    "from pathlib import Path\n",
    "from cartopy.io import shapereader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rich import print\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "from ewatercycle_wrapper_HBV import HBV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of your shapefile/region without extension:\n",
    "own_region = None  # for example: \"Rhine\"\n",
    "\n",
    "if own_region == None:  # if nothing is provided, the Rhine shapefile will be used\n",
    "    own_region = \"Rhine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapefile that describes the basin we want to study.\n",
    "path = Path.cwd()\n",
    "forcing_path = path / \"Forcing\"\n",
    "shapeFile = forcing_path / f\"{own_region}.shp\"\n",
    "\n",
    "# Location to saved forcing results from previous notebook\n",
    "forcingLocation = forcing_path / f\"{own_region}Forcing2000-2002\"\n",
    "\n",
    "# GRDC station ID for the observation station\n",
    "grdc_station_id = \"6335020\"  # GRDC station ID\n",
    "basin_name = own_region\n",
    "\n",
    "# Period of interest. \n",
    "# Make sure that GRDC data is available for this period and that it matches your forcing data\n",
    "experiment_start_time = \"2000-01-01T00:00:00Z\"\n",
    "experiment_end_time = \"2002-12-31T00:00:00Z\"\n",
    "\n",
    "# Calibration period\n",
    "calibration_start_time = \"2001-01-01T00:00:00Z\"\n",
    "calibration_end_time = \"2001-12-31T00:00:00Z\"\n",
    "\n",
    "# Validation period\n",
    "validation_start_time = \"2001-01-01T00:00:00Z\"\n",
    "validation_end_time = \"2001-12-31T00:00:00Z\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forcing was created in the previous notebook and loaded here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERA5_forcing = ewatercycle.forcing.sources[\"LumpedMakkinkForcing\"].load(forcingLocation)\n",
    "print(ERA5_forcing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create multiple HBV models with different parameters\n",
    "\n",
    "Because in eWaterCycle models are objects, we can create arrays of models. In this way, we can quickly create an array of multiple models. In case of models we call this: 'an ensemble of models'. Each model (called 'ensemble member') will be given its own parameters. So before we make the ensmeble, we have to create a set of parameters that we want to give to them. I will just use linear interpolation of the parameter space. (I suggest you come up with something smarter for your own calibration!) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9e8f254e3dd78daa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# We use the same initial conditions for all models in the ensemble\n",
    "\n",
    "s_0 = np.array([0,  100,  0,  5])\n",
    "S_names = [\"Interception storage\", \"Unsaturated Rootzone Storage\", \"Fastflow storage\", \"Groundwater storage\"]\n",
    "\n",
    "# The names of the parameters are (luckily ;-) ) also constant for all models\n",
    "p_names = [\"$I_{max}$\",  \"$C_e$\",  \"$Su_{max}$\", \"Î²\",  \"$P_{max}$\",  \"$T_{lag}$\",   \"$K_f$\",   \"$K_s$\"]\n",
    "param_names = [\"Imax\",\"Ce\",  \"Sumax\", \"beta\",  \"Pmax\",  \"Tlag\",   \"Kf\",   \"Ks\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of ensemble members in our ensemble\n",
    "N = 50\n",
    "\n",
    "p_min_initial = np.array([0,   0.2,  40,    .5,   .001,   1,     .01,  .0001])\n",
    "p_max_initial = np.array([8,    1,  800,   4,    .3,     10,    .1,   .01])\n",
    "\n",
    "\n",
    "parameters = np.zeros([8, N])\n",
    "\n",
    "# Here I use np.linspace to make a linear interpolation between the minimum and maximum parameters. \n",
    "# Realize that this means that the first model will get all low parameters and the last model will get all high parameters. \n",
    "# This can be done much smarter.\n",
    "for param in range(8):\n",
    "    parameters[param,:] = np.linspace(p_min_initial[param],p_max_initial[param],N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2a93492c16132434",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ensemble = []\n",
    "\n",
    "for counter in range(N): \n",
    "    ensemble.append(HBV(forcing=ERA5_forcing))\n",
    "    config_file, _ = ensemble[counter].setup(\n",
    "                            parameters = ','.join([str(p) for p in parameters[:,counter]]),\n",
    "                            initial_storage=','.join([str(s) for s in s_0]),\n",
    "                            cfg_dir = \"configFiles/hbv_ensembleMember_\" + str(counter),\n",
    "                               )\n",
    "    ensemble[counter].initialize(config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations and objective function\n",
    "\n",
    "We will compare each model output to observations and we need some sort of objective function to judge if the output is any good and thus determine which parameters are good for this region. I provide a basic (bad!) objective function here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the GRDS observations\n",
    "grdc_obs = ewatercycle.observation.grdc.get_grdc_data(\n",
    "    station_id=grdc_station_id,\n",
    "    start_time=experiment_start_time,\n",
    "    end_time=experiment_end_time,\n",
    ")\n",
    "\n",
    "grdc_obs = grdc_obs.to_dataframe().rename(columns={\"streamflow\": \"Observations from GRDC\"})\n",
    "print(grdc_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember from the previous notebook that we need the area of the catchment to calculate discharge in $m^3/s$ instead of $mm/day$. This time, we will do that conversion directly when we ask discharge from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapeObject = shapereader.Reader(shapeFile.absolute())\n",
    "record = next(shapeObject.records())\n",
    "shape_area = record.attributes[\"SUB_AREA\"] * 1e6\n",
    "print(\"The catchment area is:\", shape_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrationObjective(modelOutput, observation, start_calibration, end_calibration):\n",
    "    # A function that takes in two dataFrames, interpolates the model output to the\n",
    "    # observations and calculates the average absolute difference between the two.\n",
    "\n",
    "    #combine the two in one dataFrame\n",
    "    hydro_data = pd.concat([modelOutput.reindex(observation.index, method = 'ffill'), observation], axis=1)\n",
    "\n",
    "    #only select the calibration period\n",
    "    hydro_data = hydro_data[hydro_data.index > pd.to_datetime(pd.Timestamp(start_calibration).date())]\n",
    "    hydro_data = hydro_data[hydro_data.index < pd.to_datetime(pd.Timestamp(end_calibration).date())]\n",
    "\n",
    "    #calculate mean absolute difference\n",
    "\n",
    "    diff = hydro_data['Observations from GRDC'] - hydro_data['model output']\n",
    "    absDiff = np.abs(diff)\n",
    "    meanAbsDiff = np.mean(absDiff)\n",
    "\n",
    "    return meanAbsDiff\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run the entire ensemble. Note that in theory this loop can be run in parallel. If you have access to many core (or a supercomputer), this loop can be speed up considerably! For HBV this is not really a problem, but when doing calibration with larger models, this is a must."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0dd66560cf39beeb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# An object to show a progress bar, since this can take a while:\n",
    "f = IntProgress(min=0, max=N) # instantiate the bar\n",
    "display(f) # display the bar\n",
    "\n",
    "# An empty array to store the results in\n",
    "objectives = []\n",
    "\n",
    "# Loop over all ensemble members\n",
    "for ensembleMember in ensemble:\n",
    "    Q_m = []\n",
    "    time = []\n",
    "    while ensembleMember.time < ensembleMember.end_time:\n",
    "        ensembleMember.update()\n",
    "        discharge_this_timestep = ensembleMember.get_value(\"Q\") * shape_area / (1000 * 86400)\n",
    "        Q_m.append(discharge_this_timestep[0])\n",
    "        time.append(pd.Timestamp(ensembleMember.time_as_datetime.date()))\n",
    "    \n",
    "    # Calculate the objective function \n",
    "    discharge_dataframe = pd.DataFrame({'model output': Q_m}, index=pd.to_datetime(time))\n",
    "    objective_this_model = calibrationObjective(discharge_dataframe,grdc_obs,calibration_start_time,calibration_end_time)\n",
    "    objectives.append(objective_this_model)\n",
    "\n",
    "    # It is good practice to remove any variable you don't need anymore to save memory.\n",
    "    del Q_m, time, discharge_dataframe, objective_this_model\n",
    "\n",
    "    # Update progress bar\n",
    "    f.value += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finaly, just like before, we remove the models themselves to save up space and memory.\n",
    "for ensembleMember in ensemble:\n",
    "    ensembleMember.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse results\n",
    "We now have objective function results for all ensemble members! Let's make some plots!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xFigNr = 2\n",
    "yFigNr = 4\n",
    "\n",
    "fig, axs = plt.subplots(xFigNr, yFigNr,figsize = (15,15))\n",
    "\n",
    "for xFig in range(xFigNr):\n",
    "    for yFig in range(yFigNr):\n",
    "        paramCounter = xFig*yFigNr + yFig\n",
    "        axs[xFig,yFig].plot(parameters[paramCounter,:],objectives,'.')\n",
    "        axs[xFig,yFig].set_title(p_names[paramCounter])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also show the minimal values:\n",
    "parameters_minimum_index = np.argmin(np.array(objectives))\n",
    "\n",
    "parameters_minimum = parameters[:,parameters_minimum_index]\n",
    "\n",
    "print(parameters_minimum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Create your own calibration method!\n",
    "\n",
    "### Calibration \n",
    "As mentioned above: the method of choosing parameters is bad and the objective function is also far from optimal in this notebook. In this exercise, you will again an ensemble, but now you are askes to use another method to create the parameters and use Nash and Sutcliffe coefficient as objective function. Calculate both the normal NSE and the log(NSE). Compare both and see (and understand) what the difference is between them?\n",
    "\n",
    "The Nash and Sutcliffe coefficient is calculated using the formula:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "    N = 1 - \\frac{\\sum_{i=1}^{n}(Q_{o,i} - Q_{m,i})^2}{\\sum_{i=1}^{n}(O_{o,i} - \\bar{O}_{o})^2}\n",
    "\\end{equation}\n",
    "\n",
    "Where Q is discharge, the subscripts o and m stand for observed and modeled respectively, i is the time step, and the overbar indicates an average.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the code cells below to create the calibration method. Calculate the NSE value for 5000 ensemble members. Re-use the structure of the code above and edit it to create a randomly chosen parameter set and calculate the objectives NSE and Log(NSE). What is the optimal parameter set for your region?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                   Imax Ce Sumax beta Pmax   Tlag   Kf  Ks\n",
    "ParMinn = np.array([0,   0.2,  40,    .5,   .001,   0,     .01,  .0001])\n",
    "ParMaxn = np.array([8,    1,  800,   4,    .3,     10,    .1,   .01])\n",
    "Sin = np.array([0,  100,  0,  5  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random parameter set based on the ParMinn and ParMaxn array. \n",
    "# Do not use np.linspace as above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new objective function:\n",
    "\n",
    "def calibrationObjective(modelOutput, observation, start_calibration, end_calibration):\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    return nse, log_nse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An object to show a progress bar, since this can take a while:\n",
    "f = IntProgress(min=0, max=N) # instantiate the bar\n",
    "display(f) # display the bar\n",
    "\n",
    "# An empty array to store the results in\n",
    "objectives = []\n",
    "\n",
    "# Loop over all ensemble members\n",
    "for ensembleMember in ensemble:\n",
    "    Q_m = []\n",
    "    time = []\n",
    "    while ensembleMember.time < ensembleMember.end_time:\n",
    "        ensembleMember.update()\n",
    "        discharge_this_timestep = ensembleMember.get_value(\"Q\") * shape_area / (1000 * 86400)\n",
    "        Q_m.append(discharge_this_timestep[0])\n",
    "        time.append(pd.Timestamp(ensembleMember.time_as_datetime.date()))\n",
    "    \n",
    "    # Calculate the objective function \n",
    "    discharge_dataframe = pd.DataFrame({'model output': Q_m}, index=pd.to_datetime(time))\n",
    "    objective_this_model = calibrationObjective(discharge_dataframe,grdc_obs,calibration_start_time,calibration_end_time)\n",
    "    objectives.append(objective_this_model)\n",
    "\n",
    "    # It is good practice to remove any variable you don't need anymore to save memory.\n",
    "    del Q_m, time, discharge_dataframe, objective_this_model\n",
    "\n",
    "    #update progress bar\n",
    "    f.value += 1\n",
    "\n",
    "# Finaly, just like before, we remove the models themselves to save up space and memory.\n",
    "for ensembleMember in ensemble:\n",
    "    ensembleMember.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xFigNr = 2\n",
    "yFigNr = 4\n",
    "\n",
    "fig_nse, axs_nse = plt.subplots(xFigNr, yFigNr,figsize = (15,15))\n",
    "fig_nselog, axs_nselog = plt.subplots(xFigNr, yFigNr,figsize = (15,15))\n",
    "\n",
    "for xFig in range(xFigNr):\n",
    "    for yFig in range(yFigNr):\n",
    "        paramCounter = xFig*yFigNr + yFig\n",
    "        # Extract NSE and log NSE for all runs\n",
    "        nse_values = objectives[:, 0]\n",
    "        log_nse_values = objectives[:, 1]\n",
    "        \n",
    "        axs[xFig_nse,yFig_nse].plot(parameters[paramCounter,:],nse_values,'.', label='NSE')\n",
    "        axs[xFig_nse,yFig_nse].set_title(p_names[paramCounter])\n",
    "        \n",
    "        axs[xFig_nselog,yFig_nselog].plot(parameters[paramCounter,:],log_nse_values,'.', label='log NSE')\n",
    "        axs[xFig_nselog,yFig_nselog].set_title(p_names[paramCounter])\n",
    "\n",
    "        axs[xFig_nse,yFig_nse].legend()\n",
    "        axs[xFig_nselog,yFig_nselog].legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation\n",
    "If you look carefully in the first few cells of this notebook, you can see that a different calibration and validation period is added. You can extend this notebook and calculate the values of the objective function for the validation period: how does the model perform for the periods where it was not calibrated for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note on files\n",
    "\n",
    "Each model now has its own directory in the configFiles directory. If everything goes well, these are deleted with the ```finalize()``` command above. If however due to an error, they persist, you may not be able to create a new ensemble. In that case, uncomment the line in the cell below and run that. But be careful! this will remove all the files in the configFiles directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm -r configFiles/*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
